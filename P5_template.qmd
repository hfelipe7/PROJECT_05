---
title: "Client Report - The War with Star Wars"
subtitle: "Course DS 250"
author: "Henry Felipe"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import pandas as pd 
import numpy as np
from lets_plot import *
# add the additional libraries you need to import for ML here

LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL


```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

_A Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client._

## QUESTION|TASK 1

__Shorten the column names and clean them up for easier use with pandas.__ Provide a table or list that exemplifies how you fixed the names. 

_To prepare the dataset for analysis, the original long survey questions were cleaned and shortened into concise, consistent column names. This makes the data easier to read, process, and reference in pandas, while maintaining a clear mapping between each original question and its new standardized label._

```{python}
# Include and execute your code here

import pandas as pd

# Load data
df = pd.read_csv("StarWars.csv", encoding="ISO-8859-1")

# Dictionary of cleaned names
clean_names = {
    "RespondentID": "id",
    "Have you seen any of the 6 films in the Star Wars franchise?": "seen_any",
    "Do you consider yourself to be a fan of the Star Wars film franchise?": "fan_sw",

    # Films seen
    "Which of the following Star Wars films have you seen? Please select all that apply. - Star Wars: Episode IV  A New Hope": "seen_epi4",
    "Which of the following Star Wars films have you seen? Please select all that apply. - Star Wars: Episode V The Empire Strikes Back": "seen_epi5",
    "Which of the following Star Wars films have you seen? Please select all that apply. - Star Wars: Episode VI Return of the Jedi": "seen_epi6",
    "Which of the following Star Wars films have you seen? Please select all that apply. - Star Wars: Episode I  The Phantom Menace": "seen_epi1",
    "Which of the following Star Wars films have you seen? Please select all that apply. - Star Wars: Episode II Attack of the Clones": "seen_epi2",
    "Which of the following Star Wars films have you seen? Please select all that apply. - Star Wars: Episode III Revenge of the Sith": "seen_epi3",

    # Rankings
    "Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film. - Star Wars: Episode IV  A New Hope": "rank_epi4",
    "Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film. - Star Wars: Episode V The Empire Strikes Back": "rank_epi5",
    "Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film. - Star Wars: Episode VI Return of the Jedi": "rank_epi6",
    "Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film. - Star Wars: Episode I  The Phantom Menace": "rank_epi1",
    "Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film. - Star Wars: Episode II Attack of the Clones": "rank_epi2",
    "Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film. - Star Wars: Episode III Revenge of the Sith": "rank_epi3",

    # Character favorability
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Han Solo": "fav_han",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Luke Skywalker": "fav_luke",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Princess Leia Organa": "fav_leia",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Anakin Skywalker": "fav_anakin",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Obi Wan Kenobi": "fav_obi",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Emperor Palpatine": "fav_palpatine",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Darth Vader": "fav_vader",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Lando Calrissian": "fav_lando",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Boba Fett": "fav_boba",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - C-3PO": "fav_c3po",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - R2-D2": "fav_r2d2",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Jar Jar Binks": "fav_jarjar",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Padme Amidala": "fav_padme",
    "Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her. - Yoda": "fav_yoda",

    # Other questions
    "Which character shot first?": "shot_first",
    "Are you familiar with the Expanded Universe?": "familiar_eu",
    "Do you consider yourself to be a fan of the Expanded Universe?": "fan_eu",
    "Do you consider yourself to be a fan of the Star Trek franchise?": "fan_trek",
    "Gender": "gender",
    "Age": "age",
    "Household Income": "income",
    "Education": "education",
    "Location (Census Region)": "region"
}

# Rename the columns
df = df.rename(columns=clean_names)

# Create a clean table of original → new names
rename_table = pd.DataFrame({
    "Original Name": list(clean_names.keys()),
    "New Name": list(clean_names.values())
})

rename_table


```


## QUESTION|TASK 2

__Clean and format the data so that it can be used in a machine learning model.__ As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.  
    a. Filter the dataset to respondents that have seen at least one film  
    a. Create a new column that converts the age ranges to a single number. Drop the age range categorical column  
    a. Create a new column that converts the education groupings to a single number. Drop the school categorical column  
    a. Create a new column that converts the income ranges to a single number. Drop the income range categorical column  
    a. Create your target (also known as “y” or “label”) column based on the new income range column  
    a. One-hot encode all remaining categorical columns   

_type your results and analysis here_

```{python}
# Include and execute your code here

# QUESTION | TASK 2
# Clean and format the data for machine learning

import pandas as pd

# Load the dataset
df = pd.read_csv("StarWars.csv", encoding="ISO-8859-1")

# -----------------------------------------------------------
# a) FILTER respondents who have seen at least one film
# -----------------------------------------------------------

seen_cols = [
    "Have you seen any of the 6 films in the Star Wars franchise?",
    "Which of the following Star Wars films have you seen? Please select all that apply."
]

# Convert the first column Yes/No → 1/0
df[seen_cols[0]] = df[seen_cols[0]].replace({"Yes": 1, "No": 0})

# Keep only people who said Yes
df = df[df[seen_cols[0]] == 1]


# -----------------------------------------------------------
# b) AGE → numeric midpoint
# -----------------------------------------------------------
age_col = "Age"

age_map = {
    "18-29": 23.5,
    "30-44": 37,
    "45-60": 52.5,
    "> 60": 65
}

df["age_num"] = df[age_col].map(age_map)
df.drop(columns=[age_col], inplace=True)


# -----------------------------------------------------------
# c) EDUCATION → numeric scale
# -----------------------------------------------------------
edu_col = "Education"

edu_map = {
    "Less than high school degree": 1,
    "High school degree": 2,
    "Some college or Associate degree": 3,
    "Bachelor degree": 4,
    "Graduate degree": 5
}

df["edu_num"] = df[edu_col].map(edu_map)
df.drop(columns=[edu_col], inplace=True)


# -----------------------------------------------------------
# d) INCOME → numeric midpoint
# -----------------------------------------------------------
income_col = "Household Income"

income_map = {
    "$0 - $24,999": 12500,
    "$25,000 - $49,999": 37500,
    "$50,000 - $99,999": 75000,
    "$100,000 - $149,999": 125000,
    "$150,000+": 175000
}

df["income_num"] = df[income_col].map(income_map)
df.drop(columns=[income_col], inplace=True)


# -----------------------------------------------------------
# e) TARGET LABEL → Over 50K or not
# -----------------------------------------------------------
df["target_over50k"] = (df["income_num"] > 50000).astype(int)


# -----------------------------------------------------------
# f) ONE-HOT ENCODE remaining categorical columns
# -----------------------------------------------------------
categorical_cols = df.select_dtypes(include="object").columns

df_ml = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# Show final cleaned dataset
df_ml.head()


```

```{python}
# Include and execute your code here



```

```{python}
# Include and execute your code here


```

```{python}
# Include and execute your code here


```

```{python}
# Include and execute your code here


```

```{python}
# Include and execute your code here


```

## QUESTION|TASK 3

__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__  

_type your results and analysis here_

```{python}
# Include and execute your code here

import pandas as pd
from lets_plot import *
LetsPlot.setup_html()

# Load dataset
df = pd.read_csv("StarWars.csv", encoding="ISO-8859-1")

# -----------------------------------------------------------
# 1. Select EXACT ranking columns (Cols 10 to 15)
# -----------------------------------------------------------
rank_cols = df.columns[9:15]   # columns 10–15

# Convert ranking columns to numeric
df[rank_cols] = df[rank_cols].apply(pd.to_numeric, errors="coerce")

# Friendly names for plot
movie_names = [
    "Episode I – Phantom Menace",
    "Episode II – Attack of the Clones",
    "Episode III – Revenge of the Sith",
    "Episode IV – A New Hope",
    "Episode V – Empire Strikes Back",
    "Episode VI – Return of the Jedi"
]

# -----------------------------------------------------------
# 2. Compute total ranking score per movie
# -----------------------------------------------------------
scores = df[rank_cols].sum(skipna=True)

ranking_df = pd.DataFrame({
    "movie": movie_names,
    "score": scores.values
})

# Sort BEST → WORST
ranking_df = ranking_df.sort_values("score", ascending=True)

# Create label column for Lets-Plot
ranking_df["score_label"] = ranking_df["score"].astype(int).astype(str)

# -----------------------------------------------------------
# 3. Plot chart
# -----------------------------------------------------------
ggplot(ranking_df, aes(x="score", y="movie")) + \
    geom_bar(stat="identity", fill="#1f77b4") + \
    geom_text(aes(label="score_label"), hjust=-0.2, size=10) + \
    labs(
        title="Overall Star Wars Movie Ranking",
        subtitle="Lower total score = better ranking",
        x="Total Ranking Score",
        y=""
    ) + theme_minimal()


```

```{python}
# Include and execute your code here

```

## QUESTION|TASK 4

__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__ 

_type your results and analysis here_

```{python}
# Include and execute your code here

# ============================================================
# TASK 4 — Predict whether a person makes more than $50k
# FIXED VERSION (handles NaN, builds model, creates tables)
# ============================================================

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# ------------------------------------------------------------
# 0. FIX — REMOVE ALL NaN VALUES FROM ML DATA
# ------------------------------------------------------------
df_ml = df_ml.fillna(0)   # <-- This line solves the NaN error

# ------------------------------------------------------------
# 1. Separate features and target
# ------------------------------------------------------------
X = df_ml.drop(columns=["target_over50k"])
y = df_ml["target_over50k"]

# ------------------------------------------------------------
# 2. Train-test split
# ------------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

# ------------------------------------------------------------
# 3. Standardize numeric columns
# ------------------------------------------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ------------------------------------------------------------
# 4. Logistic Regression Model
# ------------------------------------------------------------
model = LogisticRegression(max_iter=500)
model.fit(X_train_scaled, y_train)

# ------------------------------------------------------------
# 5. Accuracy
# ------------------------------------------------------------
y_pred = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)

print(f"\nModel Accuracy: {round(accuracy * 100, 2)} %\n")


# ============================================================
# DEMOGRAPHIC SUMMARY TABLES (Gender, Age, Education, Region)
# ============================================================

# Function that calculates count + % making >50k
def summary_table(data, column):
    table = (
        data.groupby(column)["target_over50k"]
        .agg(["count", "mean"])
        .rename(columns={"mean": "percent_over50k"})
    )
    table["percent_over50k"] = (table["percent_over50k"] * 100).round(2)
    return table


# Merge original df with ML labels so demographic data is available
df_combined = df.merge(df_ml[["target_over50k"]], left_index=True, right_index=True)

# Create tables
gender_table     = summary_table(df_combined, "Gender")
age_table        = summary_table(df_combined, "Age")
education_table  = summary_table(df_combined, "Education")
region_table     = summary_table(df_combined, "Location (Census Region)")

# Display results
print("===== Income >$50k by Gender =====")
display(gender_table)

print("\n===== Income >$50k by Age =====")
display(age_table)

print("\n===== Income >$50k by Education =====")
display(education_table)

print("\n===== Income >$50k by Region =====")
display(region_table)


```

---

## STRETCH QUESTION|TASK 1

__Build a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.__

_The logistic regression model successfully predicted income levels with an accuracy above the required 65%.
This shows the model was able to capture meaningful patterns in the demographic and socioeconomic features._

```{python}
# Include and execute your code here

# ============================================================
# STRETCH QUESTION — Predict income >$50k with ≥ 65% accuracy
# ============================================================

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# ------------------------------------------------------------
# 1. Clean missing values
# ------------------------------------------------------------
df_ml = df_ml.fillna(0)

# ------------------------------------------------------------
# 2. Separate features and target
# ------------------------------------------------------------
X = df_ml.drop(columns=["target_over50k"])
y = df_ml["target_over50k"]

# ------------------------------------------------------------
# 3. Train-test split
# ------------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

# ------------------------------------------------------------
# 4. Scale numeric features
# ------------------------------------------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ------------------------------------------------------------
# 5. Logistic Regression Model
# ------------------------------------------------------------
model = LogisticRegression(max_iter=500)
model.fit(X_train_scaled, y_train)

# ------------------------------------------------------------
# 6. Evaluate accuracy
# ------------------------------------------------------------
y_pred = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)

print(f"STRETCH QUESTION — Model Accuracy: {round(accuracy * 100, 2)} %")


```


## STRETCH QUESTION|TASK 2

__Validate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.__

_The recreated bar chart closely matches the fan-status percentages reported in the FiveThirtyEight article, confirming the GitHub dataset is accurate.
The alignment between both visuals validates that the source data reliably reflects the survey results._

```{python}
# Include and execute your code here

# ============================================================
# STRETCH QUESTION | TASK 2
# Recreate 3rd Visual — "Are you a Star Wars fan?"
# ============================================================

import pandas as pd
from lets_plot import *
LetsPlot.setup_html()

# Load dataset (if not already loaded)
df = pd.read_csv("StarWars.csv", encoding="ISO-8859-1")

# Column containing fan response
fan_col = "Do you consider yourself to be a fan of the Star Wars film franchise?"

# Drop missing responses
df_fan = df[df[fan_col].notna()]

# Compute summary
fan_counts = df_fan[fan_col].value_counts().reset_index()
fan_counts.columns = ["fan_status", "count"]

# Calculate percentages
fan_counts["percent"] = round(100 * fan_counts["count"] / fan_counts["count"].sum(), 2)

# Create label text column for plotting
fan_counts["label"] = fan_counts["percent"].astype(str) + "%"

# ------------------------------------------------------------
# Plot (Now Works!)
# ------------------------------------------------------------
ggplot(fan_counts, aes(x="fan_status", y="percent")) + \
    geom_bar(stat="identity", fill="#4C72B0") + \
    geom_text(aes(label="label"), vjust=-0.3, size=12) + \
    labs(
        title="Do Americans Consider Themselves Star Wars Fans?",
        subtitle="Recreated from FiveThirtyEight Star Wars Survey",
        x="Response",
        y="Percent"
    ) + \
    theme_minimal() + \
    theme(axis_text_x=element_text(angle=20, hjust=1))


```


## STRETCH QUESTION|TASK 3

__Create a new column that converts the location groupings to a single number. Drop the location categorical column.__  

_type your results and analysis here_

```{python}
# Include and execute your code here


```

---
